{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "mount_file_id": "1A3uUdj2vwp47iyjrPYNFTdOkiHbp32Mf",
      "authorship_tag": "ABX9TyN27CwMUdgspyOxqv85loAq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivianfann/django/blob/master/llama_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BilG1RXEIWm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "69797a66-4db5-4813-fe5c-d43e1c833d3f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'text-generation-webui'...\n",
            "remote: Enumerating objects: 16911, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (83/83), done.\u001b[K\n",
            "remote: Total 16911 (delta 97), reused 83 (delta 54), pack-reused 16774\u001b[K\n",
            "Receiving objects: 100% (16911/16911), 26.35 MiB | 20.88 MiB/s, done.\n",
            "Resolving deltas: 100% (11906/11906), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/oobabooga/text-generation-webui"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/text-generation-webui"
      ],
      "metadata": {
        "id": "XEeMFIGcId4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c43c6385-4ab4-4670-e38b-5c8908f77a90"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "d8tUA6_GIhaZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "1497a623-1225-4b1a-97ff-9d9560a527cf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring bitsandbytes: markers 'platform_system == \"Windows\"' don't match your environment\n",
            "Ignoring llama-cpp-python: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting llama-cpp-python==0.2.50+cpuavx2 (from -r requirements.txt (line 32))\n",
            "  Downloading https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.50+cpuavx2-cp310-cp310-manylinux_2_31_x86_64.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring llama-cpp-python: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring llama-cpp-python: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting llama-cpp-python-cuda==0.2.50+cu121 (from -r requirements.txt (line 40))\n",
            "  Downloading https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.50+cu121-cp310-cp310-manylinux_2_31_x86_64.whl (60.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.4/60.4 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring llama-cpp-python-cuda-tensorcores: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda-tensorcores: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda-tensorcores: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting llama-cpp-python-cuda-tensorcores==0.2.50+cu121 (from -r requirements.txt (line 46))\n",
            "  Downloading https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda_tensorcores-0.2.50+cu121-cp310-cp310-manylinux_2_31_x86_64.whl (47.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.8/47.8 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring auto-gptq: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring auto-gptq: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring auto-gptq: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting auto-gptq==0.6.0+cu121 (from -r requirements.txt (line 52))\n",
            "  Downloading https://github.com/jllllll/AutoGPTQ/releases/download/v0.6.0/auto_gptq-0.6.0+cu121-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m100.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring exllamav2: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring exllamav2: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring exllamav2: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting exllamav2==0.0.14+cu121 (from -r requirements.txt (line 56))\n",
            "  Downloading https://github.com/oobabooga/exllamav2/releases/download/v0.0.14/exllamav2-0.0.14+cu121-cp310-cp310-linux_x86_64.whl (72.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring exllamav2: markers 'platform_system == \"Linux\" and platform_machine != \"x86_64\"' don't match your environment\n",
            "Ignoring flash-attn: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring flash-attn: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring flash-attn: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting flash-attn==2.3.4+cu122torch2.1cxx11abiFALSE (from -r requirements.txt (line 61))\n",
            "  Downloading https://github.com/Dao-AILab/flash-attention/releases/download/v2.3.4/flash_attn-2.3.4+cu122torch2.1cxx11abiFALSE-cp310-cp310-linux_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring gptq-for-llama: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring gptq-for-llama: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring gptq-for-llama: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting gptq-for-llama==0.1.1+cu121 (from -r requirements.txt (line 65))\n",
            "  Downloading https://github.com/jllllll/GPTQ-for-LLaMa-CUDA/releases/download/0.1.1/gptq_for_llama-0.1.1+cu121-cp310-cp310-linux_x86_64.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.5/739.5 kB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctransformers==0.2.27+cu121 (from -r requirements.txt (line 66))\n",
            "  Downloading https://github.com/jllllll/ctransformers-cuBLAS-wheels/releases/download/AVX2/ctransformers-0.2.27+cu121-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.27.* (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from -r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting datasets (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-2.17.1-py3-none-any.whl (536 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.7/536.7 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from -r requirements.txt (line 4))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.50.* (from -r requirements.txt (line 5))\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hqq==0.1.3 (from -r requirements.txt (line 6))\n",
            "  Downloading hqq-0.1.3.tar.gz (27 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jinja2==3.1.2 (from -r requirements.txt (line 7))\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lm_eval==0.3.0 (from -r requirements.txt (line 8))\n",
            "  Downloading lm_eval-0.3.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.5.2)\n",
            "Collecting numpy==1.26.* (from -r requirements.txt (line 10))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum==1.17.* (from -r requirements.txt (line 11))\n",
            "  Downloading optimum-1.17.1-py3-none-any.whl (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.1/407.1 kB\u001b[0m \u001b[31m37.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.5.3)\n",
            "Collecting peft==0.8.* (from -r requirements.txt (line 13))\n",
            "  Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m26.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=9.5.0 (from -r requirements.txt (line 14))\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m47.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (13.7.0)\n",
            "Requirement already satisfied: safetensors==0.4.* in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (0.1.99)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.15.2)\n",
            "Requirement already satisfied: transformers==4.37.* in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (4.37.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (4.66.2)\n",
            "Collecting wandb (from -r requirements.txt (line 24))\n",
            "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.42.* (from -r requirements.txt (line 27))\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autoawq==0.1.8 (from -r requirements.txt (line 67))\n",
            "  Downloading autoawq-0.1.8-cp310-cp310-manylinux2014_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.*->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.*->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.*->-r requirements.txt (line 1)) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.*->-r requirements.txt (line 1)) (0.20.3)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m36.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (6.1.1)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (2.6.1)\n",
            "Collecting pydub (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (4.9.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from hqq==0.1.3->-r requirements.txt (line 6))\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from hqq==0.1.3->-r requirements.txt (line 6)) (2.4.0)\n",
            "Collecting jsonlines (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.3.0->-r requirements.txt (line 8)) (2.9.0)\n",
            "Collecting openai>=0.6.4 (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading openai-1.12.0-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11>=2.6.2 (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycountry (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading pycountry-23.12.11-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytablewriter (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score>=0.0.4 (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu==1.5.0 (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.3.0->-r requirements.txt (line 8)) (1.2.2)\n",
            "Collecting sqlitedict (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Collecting zstandard (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from optimum==1.17.*->-r requirements.txt (line 11))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.17.*->-r requirements.txt (line 11)) (1.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.*->-r requirements.txt (line 22)) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.*->-r requirements.txt (line 22)) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.37.*->-r requirements.txt (line 22)) (0.15.2)\n",
            "Collecting texttable (from autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from autoawq==0.1.8->-r requirements.txt (line 67)) (0.10.2)\n",
            "Collecting attributedict (from autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading attributedict-0.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from autoawq==0.1.8->-r requirements.txt (line 67)) (3.20.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from autoawq==0.1.8->-r requirements.txt (line 67)) (0.16.0+cu121)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from autoawq==0.1.8->-r requirements.txt (line 67)) (0.9.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.6.1->gradio==3.50.*->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Collecting portalocker (from sacrebleu==1.5.0->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m17.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (3.4.1)\n",
            "Collecting multiprocess (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (3.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 16)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 16)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 16)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 16)) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 17)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 17)) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (1.60.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (3.0.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 24)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 24))\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m28.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 24))\n",
            "  Downloading sentry_sdk-1.40.6-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 24))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 24))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 24)) (1.4.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.50+cpuavx2->-r requirements.txt (line 32))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge (from auto-gptq==0.6.0+cu121->-r requirements.txt (line 52))\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting gekko (from auto-gptq==0.6.0+cu121->-r requirements.txt (line 52))\n",
            "  Downloading gekko-1.0.6-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m88.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from exllamav2==0.0.14+cu121->-r requirements.txt (line 56))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastparquet (from exllamav2==0.0.14+cu121->-r requirements.txt (line 56))\n",
            "  Downloading fastparquet-2024.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m77.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers==0.2.27+cu121->-r requirements.txt (line 66)) (9.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 24))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 17)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=0.6.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (1.3.0)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.*->-r requirements.txt (line 5)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.*->-r requirements.txt (line 5)) (2.16.2)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (3.8.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.3.0->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.3.0->-r requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.*->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.*->-r requirements.txt (line 1)) (2.1.0)\n",
            "Collecting rootpath>=0.1.0 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading rootpath-0.1.1-py3-none-any.whl (15 kB)\n",
            "Collecting inspecta>=0.1.0 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading inspecta-0.1.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting colour-runner>=0.0.5 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading colour_runner-0.1.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Collecting deepdiff>=3.3.0 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tox>=3.0.0 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading tox-4.13.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.0/155.0 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coverage>=4.5.2 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading coverage-7.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.1/234.1 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting codecov>=2.0.15 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading codecov-2.1.13-py2.py3-none-any.whl (16 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.17.*->-r requirements.txt (line 11))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cramjam>=2.3 (from fastparquet->exllamav2==0.0.14+cu121->-r requirements.txt (line 56))\n",
            "  Downloading cramjam-2.8.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading tcolorpy-0.1.4-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.3.2 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.17.*->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=0.6.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (1.2.0)\n",
            "Collecting blessings (from colour-runner>=0.0.5->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff>=3.3.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 24))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.18.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 21)) (3.2.2)\n",
            "Requirement already satisfied: platformdirs>=4.1 in /usr/local/lib/python3.10/dist-packages (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67)) (4.2.0)\n",
            "Requirement already satisfied: pluggy>=1.3 in /usr/local/lib/python3.10/dist-packages (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67)) (1.4.0)\n",
            "Collecting pyproject-api>=1.6.1 (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading pyproject_api-1.6.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67)) (2.0.1)\n",
            "Collecting virtualenv>=20.25 (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m85.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv>=20.25->tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: hqq, rouge-score, ffmpy, sqlitedict\n",
            "  Building wheel for hqq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hqq: filename=hqq-0.1.3-py3-none-any.whl size=37059 sha256=dd0b15725d6db4e385ce6b6f084f2a704aaaf7c1efb42531e72415e1e2a7e6a0\n",
            "  Stored in directory: /root/.cache/pip/wheels/b9/d3/83/9fe46924db48380f12f1c48bc12f3765370e6f7a4e6711552a\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=f83160f027dc082a490afc4aec0424e323d9902d0e6fe622b46cee3c77b40eeb\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=5343d5fcc3b730619399a48ff7e354744aa9e2611c81f4187a4521ecb3859d52\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=1f45ff7c743a6fdcfb0231ab142a46e5348de9308a441d2620a21904974cb724\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "Successfully built hqq rouge-score ffmpy sqlitedict\n",
            "Installing collected packages: texttable, sqlitedict, pydub, ninja, gptq-for-llama, ffmpy, distlib, zstandard, websockets, virtualenv, tcolorpy, smmap, setproctitle, sentry-sdk, semantic-version, rouge, python-multipart, pyproject-api, pycountry, pybind11, portalocker, Pillow, pathvalidate, orjson, ordered-set, numpy, mbstrdecoder, jsonlines, jinja2, humanfriendly, h11, einops, docker-pycreds, diskcache, dill, cramjam, coverage, colorama, blessings, aiofiles, uvicorn, typepy, tqdm-multiprocess, tox, starlette, sacrebleu, rouge-score, multiprocess, llama-cpp-python-cuda-tensorcores, llama-cpp-python-cuda, llama-cpp-python, httpcore, gitdb, gekko, deepdiff, colour-runner, coloredlogs, codecov, rootpath, httpx, GitPython, flash-attn, fastparquet, fastapi, ctransformers, bitsandbytes, accelerate, wandb, timm, openai, inspecta, gradio-client, exllamav2, datasets, DataProperty, tabledata, peft, hqq, gradio, attributedict, pytablewriter, optimum, auto-gptq, lm_eval, autoawq\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.0.1 GitPython-3.1.42 Pillow-10.2.0 accelerate-0.27.2 aiofiles-23.2.1 attributedict-0.3.0 auto-gptq-0.6.0+cu121 autoawq-0.1.8 bitsandbytes-0.42.0 blessings-1.7 codecov-2.1.13 colorama-0.4.6 coloredlogs-15.0.1 colour-runner-0.1.1 coverage-7.4.3 cramjam-2.8.1 ctransformers-0.2.27+cu121 datasets-2.17.1 deepdiff-6.7.1 dill-0.3.8 diskcache-5.6.3 distlib-0.3.8 docker-pycreds-0.4.0 einops-0.7.0 exllamav2-0.0.14+cu121 fastapi-0.110.0 fastparquet-2024.2.0 ffmpy-0.3.2 flash-attn-2.3.4 gekko-1.0.6 gitdb-4.0.11 gptq-for-llama-0.1.1+cu121 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 hqq-0.1.3 httpcore-1.0.4 httpx-0.27.0 humanfriendly-10.0 inspecta-0.1.3 jinja2-3.1.2 jsonlines-4.0.0 llama-cpp-python-0.2.50+cpuavx2 llama-cpp-python-cuda-0.2.50+cu121 llama-cpp-python-cuda-tensorcores-0.2.50+cu121 lm_eval-0.3.0 mbstrdecoder-1.1.3 multiprocess-0.70.16 ninja-1.11.1.1 numpy-1.26.4 openai-1.12.0 optimum-1.17.1 ordered-set-4.1.0 orjson-3.9.15 pathvalidate-3.2.0 peft-0.8.2 portalocker-2.8.2 pybind11-2.11.1 pycountry-23.12.11 pydub-0.25.1 pyproject-api-1.6.1 pytablewriter-1.2.0 python-multipart-0.0.9 rootpath-0.1.1 rouge-1.0.1 rouge-score-0.1.2 sacrebleu-1.5.0 semantic-version-2.10.0 sentry-sdk-1.40.6 setproctitle-1.3.3 smmap-5.0.1 sqlitedict-2.1.0 starlette-0.36.3 tabledata-1.3.3 tcolorpy-0.1.4 texttable-1.7.0 timm-0.9.16 tox-4.13.0 tqdm-multiprocess-0.0.11 typepy-1.3.2 uvicorn-0.27.1 virtualenv-20.25.1 wandb-0.16.3 websockets-11.0.3 zstandard-0.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "f6cc694264994032b1c595d096ff0528"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@main accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oye4UHe4IkHU",
        "outputId": "25e6ec06-453c-4271-d044-0322cd359e1c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git@main\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision main) to /tmp/pip-req-build-jhltxi7i\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-jhltxi7i\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 7628b3a0f40212c0f264233fc6da0d9c9cf88853\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.39.0.dev0-py3-none-any.whl size=8593989 sha256=b9bb827006649d6cedd924e1d6c488f2db88ed5455aa5b41f1f8252133f26e6c\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-ofezergs/wheels/cf/59/82/6492402e887a68975030bf8c06532260abc16abb7ccd8127cc\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.37.2\n",
            "    Uninstalling transformers-4.37.2:\n",
            "      Successfully uninstalled transformers-4.37.2\n",
            "Successfully installed transformers-4.39.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/text-generation-webui/models/CodeLlama-7b-hf"
      ],
      "metadata": {
        "id": "3cTeW2mSIvou"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/text-generation-webui/models/CodeLlama-7b-hf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxJaE4NBIxY0",
        "outputId": "7fa8e1d6-676d-4ad2-ac23-680fa9c2adb1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui/models/CodeLlama-7b-hf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/config.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/generation_config.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model-00001-of-00002.safetensors\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model-00002-of-00002.safetensors\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model.safetensors.index.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/special_tokens_map.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer.model\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer_config.json\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2PjwV1tI1-j",
        "outputId": "088b7372-d0a3-4d21-9ceb-4c3674282434"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-02-28 11:59:33--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/config.json\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.80, 18.239.50.16, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 637 [text/plain]\n",
            "Saving to: ‘config.json’\n",
            "\n",
            "\rconfig.json           0%[                    ]       0  --.-KB/s               \rconfig.json         100%[===================>]     637  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-28 11:59:33 (594 MB/s) - ‘config.json’ saved [637/637]\n",
            "\n",
            "--2024-02-28 11:59:33--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/generation_config.json\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.16, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116 [text/plain]\n",
            "Saving to: ‘generation_config.json’\n",
            "\n",
            "generation_config.j 100%[===================>]     116  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-28 11:59:33 (61.2 MB/s) - ‘generation_config.json’ saved [116/116]\n",
            "\n",
            "--2024-02-28 11:59:33--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model-00001-of-00002.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.16, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/70ab2f3d82ca81c80d2fa444db0332e534577f164951902b1b216164dff23791?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1709380773&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTM4MDc3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzcwYWIyZjNkODJjYTgxYzgwZDJmYTQ0NGRiMDMzMmU1MzQ1NzdmMTY0OTUxOTAyYjFiMjE2MTY0ZGZmMjM3OTE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=sdhC%7EAEJNmU%7EoAVHXqbqwxwDFk5f3ERZvR7WeKKLEoPYZDa9pIVD3aolu5NcmnrmY9KIXzXcG52jcDDpsJpQwA4kT4E6s3GVGAwTvgcQI3A4nCYDwNpEGMepqrPByVeZd3cggF6nYgI9AcxuQ8vrsfZlAq-x2OWo-BiQAv2JOjvJzF-uyGuRmDXuj4e6jbbGpAzeqeYoQmJcYzPsSBbRXYwI-j8rXMxn2qlCsSQV%7EcMEpN5dM1GPJ2W9icWZiP71s9KsOHChN75uxCVYP08uEOZqWhkLS5wlzoup8E1l4%7EJvCa7tJwtqeMhj52ROi8kRu5%7EtAnf2i75Hu-IbI3zHkA__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-02-28 11:59:33--  https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/70ab2f3d82ca81c80d2fa444db0332e534577f164951902b1b216164dff23791?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1709380773&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTM4MDc3M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzcwYWIyZjNkODJjYTgxYzgwZDJmYTQ0NGRiMDMzMmU1MzQ1NzdmMTY0OTUxOTAyYjFiMjE2MTY0ZGZmMjM3OTE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=sdhC%7EAEJNmU%7EoAVHXqbqwxwDFk5f3ERZvR7WeKKLEoPYZDa9pIVD3aolu5NcmnrmY9KIXzXcG52jcDDpsJpQwA4kT4E6s3GVGAwTvgcQI3A4nCYDwNpEGMepqrPByVeZd3cggF6nYgI9AcxuQ8vrsfZlAq-x2OWo-BiQAv2JOjvJzF-uyGuRmDXuj4e6jbbGpAzeqeYoQmJcYzPsSBbRXYwI-j8rXMxn2qlCsSQV%7EcMEpN5dM1GPJ2W9icWZiP71s9KsOHChN75uxCVYP08uEOZqWhkLS5wlzoup8E1l4%7EJvCa7tJwtqeMhj52ROi8kRu5%7EtAnf2i75Hu-IbI3zHkA__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.239.18.68, 18.239.18.94, 18.239.18.29, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.239.18.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9976701592 (9.3G) [binary/octet-stream]\n",
            "Saving to: ‘model-00001-of-00002.safetensors’\n",
            "\n",
            "model-00001-of-0000 100%[===================>]   9.29G   345MB/s    in 25s     \n",
            "\n",
            "2024-02-28 11:59:59 (374 MB/s) - ‘model-00001-of-00002.safetensors’ saved [9976701592/9976701592]\n",
            "\n",
            "--2024-02-28 11:59:59--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model-00002-of-00002.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.16, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/127e0cc0a92c8286a44815d42419177072fba39c472dc840d9b1f71c62076c49?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&Expires=1709380799&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTM4MDc5OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzEyN2UwY2MwYTkyYzgyODZhNDQ4MTVkNDI0MTkxNzcwNzJmYmEzOWM0NzJkYzg0MGQ5YjFmNzFjNjIwNzZjNDk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=EJF%7EuBcmN3qSe-xuHuP4ZNvH%7EY22RF93p2f94B%7E5X02cKOGeKh4%7EvnIW1Fgv2govqzInBVjnS7t3TWihYHMErKoIN3JCli480774kE5sicxM8rrGnERVM5ICWkQBhGBb9jM%7EkDshAdPUp3KVeJyxrcO5WL85fH6KVZ-USBh0gIDftf8hDSNDNsGCWUOOM9VT4xKNyD-53UjNruKZN5RtX5MMLz-XcmMBMnd7Ft5L5hEgt2uuXW4BN7KqTgzfKQIKpAlrElvevs%7EZ7r9J9GI4GreWGko8FC8%7EBuTa%7EmWm8eESxL6berf1zPnWt-fSnit0O4QVVt97ztmkD9GcbunjMg__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-02-28 11:59:59--  https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/127e0cc0a92c8286a44815d42419177072fba39c472dc840d9b1f71c62076c49?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&Expires=1709380799&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTM4MDc5OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzEyN2UwY2MwYTkyYzgyODZhNDQ4MTVkNDI0MTkxNzcwNzJmYmEzOWM0NzJkYzg0MGQ5YjFmNzFjNjIwNzZjNDk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=EJF%7EuBcmN3qSe-xuHuP4ZNvH%7EY22RF93p2f94B%7E5X02cKOGeKh4%7EvnIW1Fgv2govqzInBVjnS7t3TWihYHMErKoIN3JCli480774kE5sicxM8rrGnERVM5ICWkQBhGBb9jM%7EkDshAdPUp3KVeJyxrcO5WL85fH6KVZ-USBh0gIDftf8hDSNDNsGCWUOOM9VT4xKNyD-53UjNruKZN5RtX5MMLz-XcmMBMnd7Ft5L5hEgt2uuXW4BN7KqTgzfKQIKpAlrElvevs%7EZ7r9J9GI4GreWGko8FC8%7EBuTa%7EmWm8eESxL6berf1zPnWt-fSnit0O4QVVt97ztmkD9GcbunjMg__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.239.18.68, 18.239.18.94, 18.239.18.29, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.239.18.68|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3500425616 (3.3G) [binary/octet-stream]\n",
            "Saving to: ‘model-00002-of-00002.safetensors’\n",
            "\n",
            "model-00002-of-0000 100%[===================>]   3.26G   364MB/s    in 8.8s    \n",
            "\n",
            "2024-02-28 12:00:08 (381 MB/s) - ‘model-00002-of-00002.safetensors’ saved [3500425616/3500425616]\n",
            "\n",
            "--2024-02-28 12:00:08--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model.safetensors.index.json\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.16, 18.239.50.80, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25125 (25K) [text/plain]\n",
            "Saving to: ‘model.safetensors.index.json’\n",
            "\n",
            "model.safetensors.i 100%[===================>]  24.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-28 12:00:08 (291 MB/s) - ‘model.safetensors.index.json’ saved [25125/25125]\n",
            "\n",
            "--2024-02-28 12:00:08--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/special_tokens_map.json\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.103, 18.239.50.80, 18.239.50.49, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.103|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 411 [text/plain]\n",
            "Saving to: ‘special_tokens_map.json’\n",
            "\n",
            "special_tokens_map. 100%[===================>]     411  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-28 12:00:08 (378 MB/s) - ‘special_tokens_map.json’ saved [411/411]\n",
            "\n",
            "--2024-02-28 12:00:08--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer.json\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.49, 18.239.50.16, 18.239.50.80, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.49|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1843427 (1.8M) [text/plain]\n",
            "Saving to: ‘tokenizer.json’\n",
            "\n",
            "tokenizer.json      100%[===================>]   1.76M  2.86MB/s    in 0.6s    \n",
            "\n",
            "2024-02-28 12:00:09 (2.86 MB/s) - ‘tokenizer.json’ saved [1843427/1843427]\n",
            "\n",
            "--2024-02-28 12:00:09--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer.model\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.16, 18.239.50.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/45ccb9c8b6b561889acea59191d66986d314e7cbd6a78abc6e49b139ca91c1e6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27tokenizer.model%3B+filename%3D%22tokenizer.model%22%3B&Expires=1709378707&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTM3ODcwN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzQ1Y2NiOWM4YjZiNTYxODg5YWNlYTU5MTkxZDY2OTg2ZDMxNGU3Y2JkNmE3OGFiYzZlNDliMTM5Y2E5MWMxZTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=HmEzF-jIMVRQzHeEn0L1XVeYY5P6x%7EA4FZpt3tysABAWwP0OGpcBa2E5uehmMp%7Et4WF6Ck-AxWkCY5qjQKNgjTpAQD3xcB3CAXjv%7ETU1eBz24wNTaLRbQXOy5w3EAjCEvx-qEtrUlNgxUE6V5BbexxJGgUm-FxUqo%7E5M2V3O1au1spscvYn-IuP661ip-R%7ExjLcqrVFS4LxDrIDpO6Q7bz-RLfp07-lf5raYohfiMjAnOFCNesrH3WqQJaCJ11dPKerdr1rHUQhOCL9aey69tRi8AMuBzWigYZpZARGPzw5CWF90YvyWsvbjKvAVD1qNKLc2zOigmcNhhB6D-Mcw%7Ew__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-02-28 12:00:09--  https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/45ccb9c8b6b561889acea59191d66986d314e7cbd6a78abc6e49b139ca91c1e6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27tokenizer.model%3B+filename%3D%22tokenizer.model%22%3B&Expires=1709378707&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTM3ODcwN319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzQ1Y2NiOWM4YjZiNTYxODg5YWNlYTU5MTkxZDY2OTg2ZDMxNGU3Y2JkNmE3OGFiYzZlNDliMTM5Y2E5MWMxZTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=HmEzF-jIMVRQzHeEn0L1XVeYY5P6x%7EA4FZpt3tysABAWwP0OGpcBa2E5uehmMp%7Et4WF6Ck-AxWkCY5qjQKNgjTpAQD3xcB3CAXjv%7ETU1eBz24wNTaLRbQXOy5w3EAjCEvx-qEtrUlNgxUE6V5BbexxJGgUm-FxUqo%7E5M2V3O1au1spscvYn-IuP661ip-R%7ExjLcqrVFS4LxDrIDpO6Q7bz-RLfp07-lf5raYohfiMjAnOFCNesrH3WqQJaCJ11dPKerdr1rHUQhOCL9aey69tRi8AMuBzWigYZpZARGPzw5CWF90YvyWsvbjKvAVD1qNKLc2zOigmcNhhB6D-Mcw%7Ew__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.239.18.94, 18.239.18.29, 18.239.18.68, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.239.18.94|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 500058 (488K) [binary/octet-stream]\n",
            "Saving to: ‘tokenizer.model’\n",
            "\n",
            "tokenizer.model     100%[===================>] 488.34K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-02-28 12:00:09 (30.8 MB/s) - ‘tokenizer.model’ saved [500058/500058]\n",
            "\n",
            "--2024-02-28 12:00:09--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer_config.json\n",
            "Resolving huggingface.co (huggingface.co)... 18.239.50.80, 18.239.50.49, 18.239.50.103, ...\n",
            "Connecting to huggingface.co (huggingface.co)|18.239.50.80|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 749 [text/plain]\n",
            "Saving to: ‘tokenizer_config.json’\n",
            "\n",
            "tokenizer_config.js 100%[===================>]     749  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-28 12:00:09 (434 MB/s) - ‘tokenizer_config.json’ saved [749/749]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBHWr2mbJQHi",
        "outputId": "8ba202df-a14d-4cf0-f2d6-e2df12eb9144"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/llama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohVcccUXJc_k",
        "outputId": "c720bbf6-96d8-4a5e-a686-874ce237e3fa"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama'...\n",
            "remote: Enumerating objects: 421, done.\u001b[K\n",
            "remote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects: 100% (4/4), done.\u001b[K\n",
            "remote: Total 421 (delta 0), reused 1 (delta 0), pack-reused 417\u001b[K\n",
            "Receiving objects: 100% (421/421), 1.09 MiB | 19.99 MiB/s, done.\n",
            "Resolving deltas: 100% (218/218), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/text-generation-webui/models/llama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FTm6LM8Jsw2",
        "outputId": "8744d0f9-9ddb-4dd2-c92c-73b666e7cd8d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui/models/llama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash download.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c3UzZ_vNLAK",
        "outputId": "33a49a67-fbf9-4e4f-cb8b-60126682c00c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the URL from email: https://download.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiaHY5emlkcTQ5anQybGtkbm5laGprbmZnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTE5OTMxNX19fV19&Signature=dJuJ2NqvpH-VmbVTf%7EdQV6VQmzeTHDyIn5uXSGjb4h%7E%7EdfU0vl3Xlr73nKc1n7vrf85mGmS7Sica7Q3nwUmNtTUOibxAP0n0eC2gYctd1mTvhsfr5BqkbBhq%7E346mCYOn6o2hVzz0ZjlVHUNiBl-qXzOmvK48cihdCGwwImaNaXZeM3P6GWuWoA0kKL65eKMkF0%7EyCWZmVdO8bVlbpUOyilHIFVIiSRhTxUCmC5nFKNW%7EVstXwgXBLl2tYQM%7EX0CWXNzKvSiNkoO4pE2dM9TnBoFztYih39Xho7lE8PFMlohUaJUYpxytDuZb7yM%7EJ2Dalke-1c77jUVaBBNzaeLzg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=2405986089789604\n",
            "\n",
            "Enter the list of models to download without spaces (7B,13B,70B,7B-chat,13B-chat,70B-chat), or press Enter for all: 7B-chat\n",
            "Downloading LICENSE and Acceptable Usage Policy\n",
            "--2024-02-28 12:25:25--  https://download.llamameta.net/LICENSE?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiaHY5emlkcTQ5anQybGtkbm5laGprbmZnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTE5OTMxNX19fV19&Signature=dJuJ2NqvpH-VmbVTf%7EdQV6VQmzeTHDyIn5uXSGjb4h%7E%7EdfU0vl3Xlr73nKc1n7vrf85mGmS7Sica7Q3nwUmNtTUOibxAP0n0eC2gYctd1mTvhsfr5BqkbBhq%7E346mCYOn6o2hVzz0ZjlVHUNiBl-qXzOmvK48cihdCGwwImaNaXZeM3P6GWuWoA0kKL65eKMkF0%7EyCWZmVdO8bVlbpUOyilHIFVIiSRhTxUCmC5nFKNW%7EVstXwgXBLl2tYQM%7EX0CWXNzKvSiNkoO4pE2dM9TnBoFztYih39Xho7lE8PFMlohUaJUYpxytDuZb7yM%7EJ2Dalke-1c77jUVaBBNzaeLzg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=2405986089789604\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.62, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-02-28 12:25:25--  https://download.llamameta.net/USE_POLICY.md?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiaHY5emlkcTQ5anQybGtkbm5laGprbmZnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTE5OTMxNX19fV19&Signature=dJuJ2NqvpH-VmbVTf%7EdQV6VQmzeTHDyIn5uXSGjb4h%7E%7EdfU0vl3Xlr73nKc1n7vrf85mGmS7Sica7Q3nwUmNtTUOibxAP0n0eC2gYctd1mTvhsfr5BqkbBhq%7E346mCYOn6o2hVzz0ZjlVHUNiBl-qXzOmvK48cihdCGwwImaNaXZeM3P6GWuWoA0kKL65eKMkF0%7EyCWZmVdO8bVlbpUOyilHIFVIiSRhTxUCmC5nFKNW%7EVstXwgXBLl2tYQM%7EX0CWXNzKvSiNkoO4pE2dM9TnBoFztYih39Xho7lE8PFMlohUaJUYpxytDuZb7yM%7EJ2Dalke-1c77jUVaBBNzaeLzg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=2405986089789604\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.62, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "Downloading tokenizer\n",
            "--2024-02-28 12:25:25--  https://download.llamameta.net/tokenizer.model?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiaHY5emlkcTQ5anQybGtkbm5laGprbmZnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTE5OTMxNX19fV19&Signature=dJuJ2NqvpH-VmbVTf%7EdQV6VQmzeTHDyIn5uXSGjb4h%7E%7EdfU0vl3Xlr73nKc1n7vrf85mGmS7Sica7Q3nwUmNtTUOibxAP0n0eC2gYctd1mTvhsfr5BqkbBhq%7E346mCYOn6o2hVzz0ZjlVHUNiBl-qXzOmvK48cihdCGwwImaNaXZeM3P6GWuWoA0kKL65eKMkF0%7EyCWZmVdO8bVlbpUOyilHIFVIiSRhTxUCmC5nFKNW%7EVstXwgXBLl2tYQM%7EX0CWXNzKvSiNkoO4pE2dM9TnBoFztYih39Xho7lE8PFMlohUaJUYpxytDuZb7yM%7EJ2Dalke-1c77jUVaBBNzaeLzg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=2405986089789604\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.62, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-02-28 12:25:25--  https://download.llamameta.net/tokenizer_checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiaHY5emlkcTQ5anQybGtkbm5laGprbmZnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTE5OTMxNX19fV19&Signature=dJuJ2NqvpH-VmbVTf%7EdQV6VQmzeTHDyIn5uXSGjb4h%7E%7EdfU0vl3Xlr73nKc1n7vrf85mGmS7Sica7Q3nwUmNtTUOibxAP0n0eC2gYctd1mTvhsfr5BqkbBhq%7E346mCYOn6o2hVzz0ZjlVHUNiBl-qXzOmvK48cihdCGwwImaNaXZeM3P6GWuWoA0kKL65eKMkF0%7EyCWZmVdO8bVlbpUOyilHIFVIiSRhTxUCmC5nFKNW%7EVstXwgXBLl2tYQM%7EX0CWXNzKvSiNkoO4pE2dM9TnBoFztYih39Xho7lE8PFMlohUaJUYpxytDuZb7yM%7EJ2Dalke-1c77jUVaBBNzaeLzg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=2405986089789604\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.62, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "tokenizer.model: OK\n",
            "Downloading llama-2-7b-chat\n",
            "--2024-02-28 12:25:25--  https://download.llamameta.net/llama-2-7b-chat/consolidated.00.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiaHY5emlkcTQ5anQybGtkbm5laGprbmZnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTE5OTMxNX19fV19&Signature=dJuJ2NqvpH-VmbVTf%7EdQV6VQmzeTHDyIn5uXSGjb4h%7E%7EdfU0vl3Xlr73nKc1n7vrf85mGmS7Sica7Q3nwUmNtTUOibxAP0n0eC2gYctd1mTvhsfr5BqkbBhq%7E346mCYOn6o2hVzz0ZjlVHUNiBl-qXzOmvK48cihdCGwwImaNaXZeM3P6GWuWoA0kKL65eKMkF0%7EyCWZmVdO8bVlbpUOyilHIFVIiSRhTxUCmC5nFKNW%7EVstXwgXBLl2tYQM%7EX0CWXNzKvSiNkoO4pE2dM9TnBoFztYih39Xho7lE8PFMlohUaJUYpxytDuZb7yM%7EJ2Dalke-1c77jUVaBBNzaeLzg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=2405986089789604\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.62, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13476925163 (13G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-7b-chat/consolidated.00.pth’\n",
            "\n",
            "./llama-2-7b-chat/c 100%[===================>]  12.55G   317MB/s    in 40s     \n",
            "\n",
            "2024-02-28 12:26:06 (319 MB/s) - ‘./llama-2-7b-chat/consolidated.00.pth’ saved [13476925163/13476925163]\n",
            "\n",
            "--2024-02-28 12:26:06--  https://download.llamameta.net/llama-2-7b-chat/params.json?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiaHY5emlkcTQ5anQybGtkbm5laGprbmZnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTE5OTMxNX19fV19&Signature=dJuJ2NqvpH-VmbVTf%7EdQV6VQmzeTHDyIn5uXSGjb4h%7E%7EdfU0vl3Xlr73nKc1n7vrf85mGmS7Sica7Q3nwUmNtTUOibxAP0n0eC2gYctd1mTvhsfr5BqkbBhq%7E346mCYOn6o2hVzz0ZjlVHUNiBl-qXzOmvK48cihdCGwwImaNaXZeM3P6GWuWoA0kKL65eKMkF0%7EyCWZmVdO8bVlbpUOyilHIFVIiSRhTxUCmC5nFKNW%7EVstXwgXBLl2tYQM%7EX0CWXNzKvSiNkoO4pE2dM9TnBoFztYih39Xho7lE8PFMlohUaJUYpxytDuZb7yM%7EJ2Dalke-1c77jUVaBBNzaeLzg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=2405986089789604\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.62, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102 [application/json]\n",
            "Saving to: ‘./llama-2-7b-chat/params.json’\n",
            "\n",
            "./llama-2-7b-chat/p 100%[===================>]     102  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-28 12:26:06 (146 MB/s) - ‘./llama-2-7b-chat/params.json’ saved [102/102]\n",
            "\n",
            "--2024-02-28 12:26:06--  https://download.llamameta.net/llama-2-7b-chat/checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoiaHY5emlkcTQ5anQybGtkbm5laGprbmZnIiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTE5OTMxNX19fV19&Signature=dJuJ2NqvpH-VmbVTf%7EdQV6VQmzeTHDyIn5uXSGjb4h%7E%7EdfU0vl3Xlr73nKc1n7vrf85mGmS7Sica7Q3nwUmNtTUOibxAP0n0eC2gYctd1mTvhsfr5BqkbBhq%7E346mCYOn6o2hVzz0ZjlVHUNiBl-qXzOmvK48cihdCGwwImaNaXZeM3P6GWuWoA0kKL65eKMkF0%7EyCWZmVdO8bVlbpUOyilHIFVIiSRhTxUCmC5nFKNW%7EVstXwgXBLl2tYQM%7EX0CWXNzKvSiNkoO4pE2dM9TnBoFztYih39Xho7lE8PFMlohUaJUYpxytDuZb7yM%7EJ2Dalke-1c77jUVaBBNzaeLzg__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=2405986089789604\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 108.156.60.62, 108.156.60.32, 108.156.60.113, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|108.156.60.62|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 100 [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-7b-chat/checklist.chk’\n",
            "\n",
            "./llama-2-7b-chat/c 100%[===================>]     100  --.-KB/s    in 0s      \n",
            "\n",
            "2024-02-28 12:26:06 (13.3 MB/s) - ‘./llama-2-7b-chat/checklist.chk’ saved [100/100]\n",
            "\n",
            "Checking checksums\n",
            "consolidated.00.pth: OK\n",
            "params.json: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/text-generation-webui"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoPPR7WbJwpn",
        "outputId": "a08134fd-fe6b-440e-8d25-a26e6018093f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --share"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9dTs7gjKWVz",
        "outputId": "249b25cc-8a84-411f-ff5f-8f553bb7176e"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m12:38:58-857504\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting Text generation web UI                                            \n",
            "\u001b[2;36m12:38:58-862057\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading the extension \u001b[32m\"gallery\"\u001b[0m                                            \n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "Running on public URL: https://3b2c95efba252d903f.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\u001b[2;36m12:39:33-879618\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading \u001b[32m\"Llama-2-7b-hf\"\u001b[0m                                                    \n",
            "\u001b[2;36m12:39:33-883333\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Failed to load the model.                                                  \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/text-generation-webui/modules/ui_model_menu.py\", line 242, in load_model_wrapper\n",
            "    shared.model, shared.tokenizer = load_model(selected_model, loader)\n",
            "  File \"/content/text-generation-webui/modules/models.py\", line 87, in load_model\n",
            "    output = load_func_map[loader](model_name)\n",
            "  File \"/content/text-generation-webui/modules/models.py\", line 140, in huggingface_loader\n",
            "    config = AutoConfig.from_pretrained(path_to_model, trust_remote_code=params['trust_remote_code'])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 1117, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 631, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 686, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 369, in cached_file\n",
            "    raise EnvironmentError(\n",
            "OSError: models/Llama-2-7b-hf does not appear to have a file named config.json. Checkout 'https://huggingface.co/models/Llama-2-7b-hf/None' for available files.\n",
            "\n",
            "\u001b[2;36m12:39:43-301573\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading \u001b[32m\"Llama-2-7b-hf\"\u001b[0m                                                    \n",
            "\u001b[2;36m12:39:43-304404\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Failed to load the model.                                                  \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/text-generation-webui/modules/ui_model_menu.py\", line 242, in load_model_wrapper\n",
            "    shared.model, shared.tokenizer = load_model(selected_model, loader)\n",
            "  File \"/content/text-generation-webui/modules/models.py\", line 87, in load_model\n",
            "    output = load_func_map[loader](model_name)\n",
            "  File \"/content/text-generation-webui/modules/models.py\", line 140, in huggingface_loader\n",
            "    config = AutoConfig.from_pretrained(path_to_model, trust_remote_code=params['trust_remote_code'])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 1117, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 631, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 686, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 369, in cached_file\n",
            "    raise EnvironmentError(\n",
            "OSError: models/Llama-2-7b-hf does not appear to have a file named config.json. Checkout 'https://huggingface.co/models/Llama-2-7b-hf/None' for available files.\n",
            "\n",
            "\u001b[2;36m12:42:02-509085\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Received Ctrl+C. Shutting down Text generation web UI gracefully.          \n",
            "Killing tunnel 127.0.0.1:7860 <> https://3b2c95efba252d903f.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/text-generation-webui/models/Llama-2-7b-hf"
      ],
      "metadata": {
        "id": "9_533C4NONf2"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/text-generation-webui/models/llama-2-7b/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5N-gA0yWuElt",
        "outputId": "f0b2192f-f0f5-47cc-ba8a-1a4d4299f6bd"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui/models/llama-2-7b\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install accelerate\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3tIcuxGQq7Xr",
        "outputId": "c0f44f98-6d8c-4d3c-e79b-90429656e2a2"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_llama_weights_to_hf.py \\\n",
        "    --input_dir /llama-2-7b/  --model_size 7B --output_dir /content/text-generation-webui/models/llama-2-7hf\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X07Nkah7uRXm",
        "outputId": "a1aa9eda-2765-4f03-f81c-63cccad78b4c"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "python3: can't open file '/content/text-generation-webui/models/convert_llama_weights_to_hf.py': [Errno 2] No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/main/src/transformers/models/llama/convert_llama_weights_to_hf.py"
      ],
      "metadata": {
        "id": "DYM_Th300JPC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNydNpOTwt9f",
        "outputId": "bb21f596-2524-4ede-b69c-d72d7cc55ef7"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "python src/transformers/models/llama/convert_llama_weights_to_hf.py \\\n",
        "--input_dir /content/text-generation-webui/models/llama-2-7b \\\n",
        "--output_dir /content/text-generation-webui/models/llama-2-7hf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 551
        },
        "id": "JY6GUD0KwvC5",
        "outputId": "826536fc-5e62-47c7-a668-6d74304f1e47"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "error",
          "ename": "Exception",
          "evalue": "File `'src/transformers/models/llama/convert_llama_weights_to_hf.py'` not found.",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    713\u001b[0m             \u001b[0mfpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marg_lst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m             \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfile_finder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    715\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mIndexError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/utils/path.py\u001b[0m in \u001b[0;36mget_py_filename\u001b[0;34m(name, force_win32)\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'File `%r` not found.'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: File `'src/transformers/models/llama/convert_llama_weights_to_hf.py'` not found.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-4b3326984992>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_line_magic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'run'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'src/transformers/models/llama/convert_llama_weights_to_hf.py  --input_dir /content/text-generation-webui/models/llama-2-7b  --output_dir /content/text-generation-webui/models/llama-2-7hf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mrun_line_magic\u001b[0;34m(self, magic_name, line, _stack_depth)\u001b[0m\n\u001b[1;32m   2416\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'local_ns'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_local_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstack_depth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2417\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2418\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2419\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<decorator-gen-52>\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magic.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f, *a, **k)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \u001b[0;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/IPython/core/magics/execution.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, parameter_s, runner, file_finder)\u001b[0m\n\u001b[1;32m    723\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'nt'\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mre\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"^'.*'$\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m                 \u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'For Windows, use double quotes to wrap a filename: %run \"mypath\\\\myfile.py\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 725\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    726\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta_path\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mException\u001b[0m: File `'src/transformers/models/llama/convert_llama_weights_to_hf.py'` not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YNlbfj2DyTzY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}