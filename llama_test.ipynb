{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V100",
      "machine_shape": "hm",
      "mount_file_id": "1A3uUdj2vwp47iyjrPYNFTdOkiHbp32Mf",
      "authorship_tag": "ABX9TyOusNG2GJMaffxRsjVuaFvL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vivianfann/django/blob/master/llama_test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "BilG1RXEIWm8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e01d2de3-72eb-4aca-d51a-ccfc15151197"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'text-generation-webui'...\n",
            "remote: Enumerating objects: 17011, done.\u001b[K\n",
            "remote: Counting objects: 100% (232/232), done.\u001b[K\n",
            "remote: Compressing objects: 100% (115/115), done.\u001b[K\n",
            "remote: Total 17011 (delta 162), reused 174 (delta 117), pack-reused 16779\u001b[K\n",
            "Receiving objects: 100% (17011/17011), 26.39 MiB | 13.12 MiB/s, done.\n",
            "Resolving deltas: 100% (11976/11976), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/oobabooga/text-generation-webui"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/text-generation-webui"
      ],
      "metadata": {
        "id": "XEeMFIGcId4G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb0f9a7b-9710-4a35-e591-d4ea72556b37"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "d8tUA6_GIhaZ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "a51f1243-c6b0-416f-832b-9f91a6ee6652"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ignoring bitsandbytes: markers 'platform_system == \"Windows\"' don't match your environment\n",
            "Ignoring llama-cpp-python: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting llama-cpp-python==0.2.52+cpuavx2 (from -r requirements.txt (line 32))\n",
            "  Downloading https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/cpu/llama_cpp_python-0.2.52+cpuavx2-cp310-cp310-manylinux_2_31_x86_64.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring llama-cpp-python: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring llama-cpp-python: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting llama-cpp-python-cuda==0.2.52+cu121 (from -r requirements.txt (line 40))\n",
            "  Downloading https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda-0.2.52+cu121-cp310-cp310-manylinux_2_31_x86_64.whl (65.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.2/65.2 MB\u001b[0m \u001b[31m22.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring llama-cpp-python-cuda-tensorcores: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda-tensorcores: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring llama-cpp-python-cuda-tensorcores: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting llama-cpp-python-cuda-tensorcores==0.2.52+cu121 (from -r requirements.txt (line 46))\n",
            "  Downloading https://github.com/oobabooga/llama-cpp-python-cuBLAS-wheels/releases/download/textgen-webui/llama_cpp_python_cuda_tensorcores-0.2.52+cu121-cp310-cp310-manylinux_2_31_x86_64.whl (52.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.6/52.6 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring auto-gptq: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring auto-gptq: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring auto-gptq: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting auto-gptq==0.6.0+cu121 (from -r requirements.txt (line 52))\n",
            "  Downloading https://github.com/jllllll/AutoGPTQ/releases/download/v0.6.0/auto_gptq-0.6.0+cu121-cp310-cp310-linux_x86_64.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring exllamav2: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring exllamav2: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring exllamav2: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting exllamav2==0.0.14+cu121 (from -r requirements.txt (line 56))\n",
            "  Downloading https://github.com/oobabooga/exllamav2/releases/download/v0.0.14/exllamav2-0.0.14+cu121-cp310-cp310-linux_x86_64.whl (72.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 MB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring exllamav2: markers 'platform_system == \"Linux\" and platform_machine != \"x86_64\"' don't match your environment\n",
            "Ignoring flash-attn: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring flash-attn: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring flash-attn: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting flash-attn==2.3.4+cu122torch2.1cxx11abiFALSE (from -r requirements.txt (line 61))\n",
            "  Downloading https://github.com/Dao-AILab/flash-attention/releases/download/v2.3.4/flash_attn-2.3.4+cu122torch2.1cxx11abiFALSE-cp310-cp310-linux_x86_64.whl (57.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.4/57.4 MB\u001b[0m \u001b[31m23.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hIgnoring gptq-for-llama: markers 'platform_system == \"Windows\" and python_version == \"3.11\"' don't match your environment\n",
            "Ignoring gptq-for-llama: markers 'platform_system == \"Windows\" and python_version == \"3.10\"' don't match your environment\n",
            "Ignoring gptq-for-llama: markers 'platform_system == \"Linux\" and platform_machine == \"x86_64\" and python_version == \"3.11\"' don't match your environment\n",
            "Collecting gptq-for-llama==0.1.1+cu121 (from -r requirements.txt (line 65))\n",
            "  Downloading https://github.com/jllllll/GPTQ-for-LLaMa-CUDA/releases/download/0.1.1/gptq_for_llama-0.1.1+cu121-cp310-cp310-linux_x86_64.whl (739 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.5/739.5 kB\u001b[0m \u001b[31m54.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ctransformers==0.2.27+cu121 (from -r requirements.txt (line 66))\n",
            "  Downloading https://github.com/jllllll/ctransformers-cuBLAS-wheels/releases/download/AVX2/ctransformers-0.2.27+cu121-py3-none-any.whl (15.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.5/15.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting accelerate==0.27.* (from -r requirements.txt (line 1))\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting colorama (from -r requirements.txt (line 2))\n",
            "  Downloading colorama-0.4.6-py2.py3-none-any.whl (25 kB)\n",
            "Collecting datasets (from -r requirements.txt (line 3))\n",
            "  Downloading datasets-2.18.0-py3-none-any.whl (510 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m510.5/510.5 kB\u001b[0m \u001b[31m25.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting einops (from -r requirements.txt (line 4))\n",
            "  Downloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gradio==3.50.* (from -r requirements.txt (line 5))\n",
            "  Downloading gradio-3.50.2-py3-none-any.whl (20.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.3/20.3 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hqq==0.1.3.post1 (from -r requirements.txt (line 6))\n",
            "  Downloading hqq-0.1.3.post1.tar.gz (28 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting jinja2==3.1.2 (from -r requirements.txt (line 7))\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting lm_eval==0.3.0 (from -r requirements.txt (line 8))\n",
            "  Downloading lm_eval-0.3.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (3.5.2)\n",
            "Collecting numpy==1.26.* (from -r requirements.txt (line 10))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting optimum==1.17.* (from -r requirements.txt (line 11))\n",
            "  Downloading optimum-1.17.1-py3-none-any.whl (407 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m407.1/407.1 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (1.5.3)\n",
            "Collecting peft==0.8.* (from -r requirements.txt (line 13))\n",
            "  Downloading peft-0.8.2-py3-none-any.whl (183 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.4/183.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow>=9.5.0 (from -r requirements.txt (line 14))\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m28.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 15)) (6.0.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 16)) (2.31.0)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (13.7.0)\n",
            "Requirement already satisfied: safetensors==0.4.* in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 18)) (0.4.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (1.11.4)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (0.1.99)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (2.15.2)\n",
            "Requirement already satisfied: transformers==4.38.* in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 22)) (4.38.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 23)) (4.66.2)\n",
            "Collecting wandb (from -r requirements.txt (line 24))\n",
            "  Downloading wandb-0.16.3-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m91.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bitsandbytes==0.42.* (from -r requirements.txt (line 27))\n",
            "  Downloading bitsandbytes-0.42.0-py3-none-any.whl (105.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.0/105.0 MB\u001b[0m \u001b[31m15.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting autoawq==0.1.8 (from -r requirements.txt (line 67))\n",
            "  Downloading autoawq-0.1.8-cp310-cp310-manylinux2014_x86_64.whl (20.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/20.5 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.*->-r requirements.txt (line 1)) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.*->-r requirements.txt (line 1)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.*->-r requirements.txt (line 1)) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate==0.27.*->-r requirements.txt (line 1)) (0.20.3)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (4.2.2)\n",
            "Collecting fastapi (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading fastapi-0.110.0-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ffmpy (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading ffmpy-0.3.2.tar.gz (5.5 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting gradio-client==0.6.1 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading gradio_client-0.6.1-py3-none-any.whl (299 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.2/299.2 kB\u001b[0m \u001b[31m33.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting httpx (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (6.1.2)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (3.7.1)\n",
            "Collecting orjson~=3.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading orjson-3.9.15-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (2.6.3)\n",
            "Collecting pydub (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting python-multipart (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio==3.50.*->-r requirements.txt (line 5)) (4.10.0)\n",
            "Collecting uvicorn>=0.14.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading uvicorn-0.27.1-py3-none-any.whl (60 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting websockets<12.0,>=10.0 (from gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading websockets-11.0.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (129 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.9/129.9 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting timm (from hqq==0.1.3.post1->-r requirements.txt (line 6))\n",
            "  Downloading timm-0.9.16-py3-none-any.whl (2.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m98.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from hqq==0.1.3.post1->-r requirements.txt (line 6)) (2.4.0)\n",
            "Collecting jsonlines (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.3.0->-r requirements.txt (line 8)) (2.9.0)\n",
            "Collecting openai>=0.6.4 (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading openai-1.13.3-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.4/227.4 kB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pybind11>=2.6.2 (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading pybind11-2.11.1-py3-none-any.whl (227 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.7/227.7 kB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycountry (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading pycountry-23.12.11-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m96.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytablewriter (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading pytablewriter-1.2.0-py3-none-any.whl (111 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.1/111.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge-score>=0.0.4 (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting sacrebleu==1.5.0 (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading sacrebleu-1.5.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.6/65.6 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from lm_eval==0.3.0->-r requirements.txt (line 8)) (1.2.2)\n",
            "Collecting sqlitedict (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading sqlitedict-2.1.0.tar.gz (21 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting tqdm-multiprocess (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading tqdm_multiprocess-0.0.11-py3-none-any.whl (9.8 kB)\n",
            "Collecting zstandard (from lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading zstandard-0.22.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coloredlogs (from optimum==1.17.*->-r requirements.txt (line 11))\n",
            "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from optimum==1.17.*->-r requirements.txt (line 11)) (1.12)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.*->-r requirements.txt (line 22)) (3.13.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.*->-r requirements.txt (line 22)) (2023.12.25)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.38.*->-r requirements.txt (line 22)) (0.15.2)\n",
            "Collecting texttable (from autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: toml in /usr/local/lib/python3.10/dist-packages (from autoawq==0.1.8->-r requirements.txt (line 67)) (0.10.2)\n",
            "Collecting attributedict (from autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading attributedict-0.3.0-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from autoawq==0.1.8->-r requirements.txt (line 67)) (3.20.3)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (from autoawq==0.1.8->-r requirements.txt (line 67)) (0.16.0+cu121)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from autoawq==0.1.8->-r requirements.txt (line 67)) (0.9.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.6.1->gradio==3.50.*->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Collecting portalocker (from sacrebleu==1.5.0->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading portalocker-2.8.2-py3-none-any.whl (17 kB)\n",
            "Requirement already satisfied: pyarrow>=12.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (14.0.2)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (0.6)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (3.4.1)\n",
            "Collecting multiprocess (from datasets->-r requirements.txt (line 3))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets->-r requirements.txt (line 3)) (3.9.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->-r requirements.txt (line 12)) (2023.4)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 16)) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 16)) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 16)) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->-r requirements.txt (line 16)) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 17)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->-r requirements.txt (line 17)) (2.16.1)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (1.62.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (2.27.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (1.2.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (67.7.2)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (1.16.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard->-r requirements.txt (line 21)) (3.0.1)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 24)) (8.1.7)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb->-r requirements.txt (line 24))\n",
            "  Downloading GitPython-3.1.42-py3-none-any.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.4/195.4 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentry-sdk>=1.0.0 (from wandb->-r requirements.txt (line 24))\n",
            "  Downloading sentry_sdk-1.40.6-py2.py3-none-any.whl (258 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/258.5 kB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb->-r requirements.txt (line 24))\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Collecting setproctitle (from wandb->-r requirements.txt (line 24))\n",
            "  Downloading setproctitle-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb->-r requirements.txt (line 24)) (1.4.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.52+cpuavx2->-r requirements.txt (line 32))\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rouge (from auto-gptq==0.6.0+cu121->-r requirements.txt (line 52))\n",
            "  Downloading rouge-1.0.1-py3-none-any.whl (13 kB)\n",
            "Collecting gekko (from auto-gptq==0.6.0+cu121->-r requirements.txt (line 52))\n",
            "  Downloading gekko-1.0.6-py3-none-any.whl (12.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m83.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ninja (from exllamav2==0.0.14+cu121->-r requirements.txt (line 56))\n",
            "  Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/307.2 kB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting fastparquet (from exllamav2==0.0.14+cu121->-r requirements.txt (line 56))\n",
            "  Downloading fastparquet-2024.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: py-cpuinfo<10.0.0,>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from ctransformers==0.2.27+cu121->-r requirements.txt (line 66)) (9.0.0)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets->-r requirements.txt (line 3)) (4.0.3)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 24))\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 21)) (1.3.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->-r requirements.txt (line 17)) (0.1.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio==3.50.*->-r requirements.txt (line 5)) (3.1.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=0.6.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=0.6.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (1.3.1)\n",
            "Collecting httpcore==1.* (from httpx->gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading httpcore-1.0.4-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx->gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.*->-r requirements.txt (line 5)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,<3.0.0,>=1.7.4->gradio==3.50.*->-r requirements.txt (line 5)) (2.16.3)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from rouge-score>=0.0.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (3.8.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.3.0->-r requirements.txt (line 8)) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.24.1->lm_eval==0.3.0->-r requirements.txt (line 8)) (3.3.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.*->-r requirements.txt (line 1)) (3.2.1)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate==0.27.*->-r requirements.txt (line 1)) (2.1.0)\n",
            "Collecting rootpath>=0.1.0 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading rootpath-0.1.1-py3-none-any.whl (15 kB)\n",
            "Collecting inspecta>=0.1.0 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading inspecta-0.1.3-py3-none-any.whl (9.2 kB)\n",
            "Collecting colour-runner>=0.0.5 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading colour_runner-0.1.1-py2.py3-none-any.whl (3.7 kB)\n",
            "Collecting deepdiff>=3.3.0 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading deepdiff-6.7.1-py3-none-any.whl (76 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.6/76.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tox>=3.0.0 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading tox-4.13.0-py3-none-any.whl (155 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.0/155.0 kB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting coverage>=4.5.2 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading coverage-7.4.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (234 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.1/234.1 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting codecov>=2.0.15 (from attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading codecov-2.1.13-py2.py3-none-any.whl (16 kB)\n",
            "Collecting humanfriendly>=9.1 (from coloredlogs->optimum==1.17.*->-r requirements.txt (line 11))\n",
            "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting starlette<0.37.0,>=0.36.3 (from fastapi->gradio==3.50.*->-r requirements.txt (line 5))\n",
            "  Downloading starlette-0.36.3-py3-none-any.whl (71 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting cramjam>=2.3 (from fastparquet->exllamav2==0.0.14+cu121->-r requirements.txt (line 56))\n",
            "  Downloading cramjam-2.8.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m94.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting DataProperty<2,>=1.0.1 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading DataProperty-1.0.1-py3-none-any.whl (27 kB)\n",
            "Collecting mbstrdecoder<2,>=1.0.0 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading mbstrdecoder-1.1.3-py3-none-any.whl (7.8 kB)\n",
            "Collecting pathvalidate<4,>=2.3.0 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading pathvalidate-3.2.0-py3-none-any.whl (23 kB)\n",
            "Collecting tabledata<2,>=1.3.1 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading tabledata-1.3.3-py3-none-any.whl (11 kB)\n",
            "Collecting tcolorpy<1,>=0.0.5 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading tcolorpy-0.1.4-py3-none-any.whl (7.9 kB)\n",
            "Collecting typepy[datetime]<2,>=1.3.2 (from pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8))\n",
            "  Downloading typepy-1.3.2-py3-none-any.whl (31 kB)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->optimum==1.17.*->-r requirements.txt (line 11)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai>=0.6.4->lm_eval==0.3.0->-r requirements.txt (line 8)) (1.2.0)\n",
            "Collecting blessings (from colour-runner>=0.0.5->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading blessings-1.7-py3-none-any.whl (18 kB)\n",
            "Collecting ordered-set<4.2.0,>=4.0.2 (from deepdiff>=3.3.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading ordered_set-4.1.0-py3-none-any.whl (7.6 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb->-r requirements.txt (line 24))\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio==3.50.*->-r requirements.txt (line 5)) (0.18.0)\n",
            "Requirement already satisfied: chardet<6,>=3.0.4 in /usr/local/lib/python3.10/dist-packages (from mbstrdecoder<2,>=1.0.0->pytablewriter->lm_eval==0.3.0->-r requirements.txt (line 8)) (5.2.0)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->-r requirements.txt (line 21)) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard->-r requirements.txt (line 21)) (3.2.2)\n",
            "Requirement already satisfied: platformdirs>=4.1 in /usr/local/lib/python3.10/dist-packages (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67)) (4.2.0)\n",
            "Requirement already satisfied: pluggy>=1.3 in /usr/local/lib/python3.10/dist-packages (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67)) (1.4.0)\n",
            "Collecting pyproject-api>=1.6.1 (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading pyproject_api-1.6.1-py3-none-any.whl (12 kB)\n",
            "Requirement already satisfied: tomli>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67)) (2.0.1)\n",
            "Collecting virtualenv>=20.25 (from tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading virtualenv-20.25.1-py3-none-any.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m107.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting distlib<1,>=0.3.7 (from virtualenv>=20.25->tox>=3.0.0->attributedict->autoawq==0.1.8->-r requirements.txt (line 67))\n",
            "  Downloading distlib-0.3.8-py2.py3-none-any.whl (468 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m468.9/468.9 kB\u001b[0m \u001b[31m48.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: hqq, rouge-score, ffmpy, sqlitedict\n",
            "  Building wheel for hqq (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hqq: filename=hqq-0.1.3.post1-py3-none-any.whl size=37537 sha256=e1048d06aea8439263d584bcc2955fedc9fb903d62ce521a079ed278c088f313\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/d5/9c/dd504d3695dffe1a81cdd628d36aea200496fcf2ac5ea3649e\n",
            "  Building wheel for rouge-score (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24933 sha256=c2d33b08ba7abcefc60696e9e7d708e187a702c576fda3da605bc76e64c9d9ad\n",
            "  Stored in directory: /root/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
            "  Building wheel for ffmpy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ffmpy: filename=ffmpy-0.3.2-py3-none-any.whl size=5584 sha256=c408f2381932bec4d16d70610f1822298c693bd2cced4f42c60f83cf60cd87e1\n",
            "  Stored in directory: /root/.cache/pip/wheels/bd/65/9a/671fc6dcde07d4418df0c592f8df512b26d7a0029c2a23dd81\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-2.1.0-py3-none-any.whl size=16863 sha256=6d38a122d16e7dfe9e2188765eabdd7ee81750670db049b43b55cc7bb1a5eba4\n",
            "  Stored in directory: /root/.cache/pip/wheels/79/d6/e7/304e0e6cb2221022c26d8161f7c23cd4f259a9e41e8bbcfabd\n",
            "Successfully built hqq rouge-score ffmpy sqlitedict\n",
            "Installing collected packages: texttable, sqlitedict, pydub, ninja, gptq-for-llama, ffmpy, distlib, zstandard, websockets, virtualenv, tcolorpy, smmap, setproctitle, sentry-sdk, semantic-version, rouge, python-multipart, pyproject-api, pycountry, pybind11, portalocker, Pillow, pathvalidate, orjson, ordered-set, numpy, mbstrdecoder, jsonlines, jinja2, humanfriendly, h11, einops, docker-pycreds, diskcache, dill, cramjam, coverage, colorama, blessings, aiofiles, uvicorn, typepy, tqdm-multiprocess, tox, starlette, sacrebleu, rouge-score, multiprocess, llama-cpp-python-cuda-tensorcores, llama-cpp-python-cuda, llama-cpp-python, httpcore, gitdb, gekko, deepdiff, colour-runner, coloredlogs, codecov, rootpath, httpx, GitPython, flash-attn, fastparquet, fastapi, ctransformers, bitsandbytes, accelerate, wandb, timm, openai, inspecta, gradio-client, exllamav2, datasets, DataProperty, tabledata, peft, hqq, gradio, attributedict, pytablewriter, optimum, auto-gptq, lm_eval, autoawq\n",
            "  Attempting uninstall: Pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.3\n",
            "    Uninstalling Jinja2-3.1.3:\n",
            "      Successfully uninstalled Jinja2-3.1.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "imageio 2.31.6 requires pillow<10.1.0,>=8.3.2, but you have pillow 10.2.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed DataProperty-1.0.1 GitPython-3.1.42 Pillow-10.2.0 accelerate-0.27.2 aiofiles-23.2.1 attributedict-0.3.0 auto-gptq-0.6.0+cu121 autoawq-0.1.8 bitsandbytes-0.42.0 blessings-1.7 codecov-2.1.13 colorama-0.4.6 coloredlogs-15.0.1 colour-runner-0.1.1 coverage-7.4.3 cramjam-2.8.2 ctransformers-0.2.27+cu121 datasets-2.18.0 deepdiff-6.7.1 dill-0.3.8 diskcache-5.6.3 distlib-0.3.8 docker-pycreds-0.4.0 einops-0.7.0 exllamav2-0.0.14+cu121 fastapi-0.110.0 fastparquet-2024.2.0 ffmpy-0.3.2 flash-attn-2.3.4 gekko-1.0.6 gitdb-4.0.11 gptq-for-llama-0.1.1+cu121 gradio-3.50.2 gradio-client-0.6.1 h11-0.14.0 hqq-0.1.3.post1 httpcore-1.0.4 httpx-0.27.0 humanfriendly-10.0 inspecta-0.1.3 jinja2-3.1.2 jsonlines-4.0.0 llama-cpp-python-0.2.52+cpuavx2 llama-cpp-python-cuda-0.2.52+cu121 llama-cpp-python-cuda-tensorcores-0.2.52+cu121 lm_eval-0.3.0 mbstrdecoder-1.1.3 multiprocess-0.70.16 ninja-1.11.1.1 numpy-1.26.4 openai-1.13.3 optimum-1.17.1 ordered-set-4.1.0 orjson-3.9.15 pathvalidate-3.2.0 peft-0.8.2 portalocker-2.8.2 pybind11-2.11.1 pycountry-23.12.11 pydub-0.25.1 pyproject-api-1.6.1 pytablewriter-1.2.0 python-multipart-0.0.9 rootpath-0.1.1 rouge-1.0.1 rouge-score-0.1.2 sacrebleu-1.5.0 semantic-version-2.10.0 sentry-sdk-1.40.6 setproctitle-1.3.3 smmap-5.0.1 sqlitedict-2.1.0 starlette-0.36.3 tabledata-1.3.3 tcolorpy-0.1.4 texttable-1.7.0 timm-0.9.16 tox-4.13.0 tqdm-multiprocess-0.0.11 typepy-1.3.2 uvicorn-0.27.1 virtualenv-20.25.1 wandb-0.16.3 websockets-11.0.3 zstandard-0.22.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL"
                ]
              },
              "id": "ee4ce9ab92ec4c72b3d405f1e5a33f09"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git@main accelerate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oye4UHe4IkHU",
        "outputId": "ab5d1b75-987d-4ff7-9411-8aeb05badab4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git@main\n",
            "  Cloning https://github.com/huggingface/transformers.git (to revision main) to /tmp/pip-req-build-ojg4t7ja\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-ojg4t7ja\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 1681a6d452b60ff3652a96f03541dfa491124192\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (2024.2.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.39.0.dev0-py3-none-any.whl size=8593883 sha256=85ab518fa5294daf8df82e3ea78af3a6aa81c82be57f4fab58a54fab7741e023\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-6lx9_rgm/wheels/cf/59/82/6492402e887a68975030bf8c06532260abc16abb7ccd8127cc\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.38.1\n",
            "    Uninstalling transformers-4.38.1:\n",
            "      Successfully uninstalled transformers-4.38.1\n",
            "Successfully installed transformers-4.39.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/text-generation-webui/models/CodeLlama-7b-hf"
      ],
      "metadata": {
        "id": "3cTeW2mSIvou"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/text-generation-webui/models/CodeLlama-7b-hf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yxJaE4NBIxY0",
        "outputId": "d23ff50c-277a-41df-9fe5-0dcce0384005"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui/models/CodeLlama-7b-hf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/config.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/generation_config.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model-00001-of-00002.safetensors\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model-00002-of-00002.safetensors\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model.safetensors.index.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/special_tokens_map.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer.json\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer.model\n",
        "!wget https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer_config.json\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b2PjwV1tI1-j",
        "outputId": "23d379a3-617a-4d80-d6a7-4826df6937e1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-04 12:25:01--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/config.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.5, 13.35.7.38, 13.35.7.57, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 637 [text/plain]\n",
            "Saving to: ‘config.json’\n",
            "\n",
            "config.json         100%[===================>]     637  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-04 12:25:02 (637 MB/s) - ‘config.json’ saved [637/637]\n",
            "\n",
            "--2024-03-04 12:25:02--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/generation_config.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.38, 13.35.7.5, 13.35.7.81, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 116 [text/plain]\n",
            "Saving to: ‘generation_config.json’\n",
            "\n",
            "generation_config.j 100%[===================>]     116  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-04 12:25:02 (71.2 MB/s) - ‘generation_config.json’ saved [116/116]\n",
            "\n",
            "--2024-03-04 12:25:02--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model-00001-of-00002.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.38, 13.35.7.5, 13.35.7.81, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.38|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/70ab2f3d82ca81c80d2fa444db0332e534577f164951902b1b216164dff23791?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1709814302&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTgxNDMwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzcwYWIyZjNkODJjYTgxYzgwZDJmYTQ0NGRiMDMzMmU1MzQ1NzdmMTY0OTUxOTAyYjFiMjE2MTY0ZGZmMjM3OTE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=dcbTLx9TL7VpBt-fHSwIscIO4ww09UKXknm0myAAZbDoE8Zjn9ufv6%7EIeMc0Dxtr4lcWD6-xtrkvGiFsQ7cf3gUy0Aypfp73ijxvfxxyr2%7EcmxwE%7E-bclnVI2XK1lPfmLfg9SFXDVzyshLnrhSADYbgUFSF4DKNx92Zk8sc2trvIkkKAtFIabUkH0HXQnicgjgJ5W%7EKy7zfZP7PIpUKACtS-sIu%7E-74D-lZasgiq5hCY3sb8OEkQDn40Jc35nU%7EcGFup7iezWNzAo2Qg0cA%7ErbJ9vihRwJZxLvG8dw5EPeT3HUdepogZm2rmB1p9hulUG-iL1e534kRkVXHZkTmvTw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-03-04 12:25:02--  https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/70ab2f3d82ca81c80d2fa444db0332e534577f164951902b1b216164dff23791?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00001-of-00002.safetensors%3B+filename%3D%22model-00001-of-00002.safetensors%22%3B&Expires=1709814302&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTgxNDMwMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzcwYWIyZjNkODJjYTgxYzgwZDJmYTQ0NGRiMDMzMmU1MzQ1NzdmMTY0OTUxOTAyYjFiMjE2MTY0ZGZmMjM3OTE%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=dcbTLx9TL7VpBt-fHSwIscIO4ww09UKXknm0myAAZbDoE8Zjn9ufv6%7EIeMc0Dxtr4lcWD6-xtrkvGiFsQ7cf3gUy0Aypfp73ijxvfxxyr2%7EcmxwE%7E-bclnVI2XK1lPfmLfg9SFXDVzyshLnrhSADYbgUFSF4DKNx92Zk8sc2trvIkkKAtFIabUkH0HXQnicgjgJ5W%7EKy7zfZP7PIpUKACtS-sIu%7E-74D-lZasgiq5hCY3sb8OEkQDn40Jc35nU%7EcGFup7iezWNzAo2Qg0cA%7ErbJ9vihRwJZxLvG8dw5EPeT3HUdepogZm2rmB1p9hulUG-iL1e534kRkVXHZkTmvTw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.35.7.14, 13.35.7.99, 13.35.7.93, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.35.7.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 9976701592 (9.3G) [binary/octet-stream]\n",
            "Saving to: ‘model-00001-of-00002.safetensors’\n",
            "\n",
            "model-00001-of-0000 100%[===================>]   9.29G  19.0MB/s    in 8m 29s  \n",
            "\n",
            "2024-03-04 12:33:32 (18.7 MB/s) - ‘model-00001-of-00002.safetensors’ saved [9976701592/9976701592]\n",
            "\n",
            "--2024-03-04 12:33:32--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model-00002-of-00002.safetensors\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.57, 13.35.7.38, 13.35.7.5, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.57|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/127e0cc0a92c8286a44815d42419177072fba39c472dc840d9b1f71c62076c49?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&Expires=1709814812&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTgxNDgxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzEyN2UwY2MwYTkyYzgyODZhNDQ4MTVkNDI0MTkxNzcwNzJmYmEzOWM0NzJkYzg0MGQ5YjFmNzFjNjIwNzZjNDk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Un57nEGosqZo3wopRPK4o4w8xWl7NVnkcTjNgZKrlkw5jqLY7Wo33shuphkgjloewJJoBNJqOhPNj1L5Dsq1VXc207nIHW7YgAfB-adS6k1KEHESu-H6fYp0b%7EPjcDy7ELAu7tkqWODrQhGed0eX3EserhVkHlcg1UC3S%7EhfDG5uctAOCPDQW6EWJ23ky1QjX%7EWzpn4b3KKpEnFL9cG1xIMfatAeAgG2ZJY7MUpHxav0ocjLsesej%7EDuol1Ptm9QDUHmA5nyd-m20SxdJgepxOu8JEswvuvpiSKcn3Dz86dahDKFLSwn6p3iUOBlcXk97PSet6GFflOg-LlDXhZQ2g__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-03-04 12:33:32--  https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/127e0cc0a92c8286a44815d42419177072fba39c472dc840d9b1f71c62076c49?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27model-00002-of-00002.safetensors%3B+filename%3D%22model-00002-of-00002.safetensors%22%3B&Expires=1709814812&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTgxNDgxMn19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzEyN2UwY2MwYTkyYzgyODZhNDQ4MTVkNDI0MTkxNzcwNzJmYmEzOWM0NzJkYzg0MGQ5YjFmNzFjNjIwNzZjNDk%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=Un57nEGosqZo3wopRPK4o4w8xWl7NVnkcTjNgZKrlkw5jqLY7Wo33shuphkgjloewJJoBNJqOhPNj1L5Dsq1VXc207nIHW7YgAfB-adS6k1KEHESu-H6fYp0b%7EPjcDy7ELAu7tkqWODrQhGed0eX3EserhVkHlcg1UC3S%7EhfDG5uctAOCPDQW6EWJ23ky1QjX%7EWzpn4b3KKpEnFL9cG1xIMfatAeAgG2ZJY7MUpHxav0ocjLsesej%7EDuol1Ptm9QDUHmA5nyd-m20SxdJgepxOu8JEswvuvpiSKcn3Dz86dahDKFLSwn6p3iUOBlcXk97PSet6GFflOg-LlDXhZQ2g__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.35.7.93, 13.35.7.113, 13.35.7.14, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.35.7.93|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3500425616 (3.3G) [binary/octet-stream]\n",
            "Saving to: ‘model-00002-of-00002.safetensors’\n",
            "\n",
            "model-00002-of-0000 100%[===================>]   3.26G  18.5MB/s    in 3m 2s   \n",
            "\n",
            "2024-03-04 12:36:35 (18.3 MB/s) - ‘model-00002-of-00002.safetensors’ saved [3500425616/3500425616]\n",
            "\n",
            "--2024-03-04 12:36:35--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/model.safetensors.index.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.5, 13.35.7.38, 13.35.7.81, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 25125 (25K) [text/plain]\n",
            "Saving to: ‘model.safetensors.index.json’\n",
            "\n",
            "model.safetensors.i 100%[===================>]  24.54K  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-04 12:36:36 (57.0 MB/s) - ‘model.safetensors.index.json’ saved [25125/25125]\n",
            "\n",
            "--2024-03-04 12:36:36--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/special_tokens_map.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.5, 13.35.7.38, 13.35.7.81, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 411 [text/plain]\n",
            "Saving to: ‘special_tokens_map.json’\n",
            "\n",
            "special_tokens_map. 100%[===================>]     411  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-04 12:36:36 (139 MB/s) - ‘special_tokens_map.json’ saved [411/411]\n",
            "\n",
            "--2024-03-04 12:36:36--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.5, 13.35.7.38, 13.35.7.81, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1843427 (1.8M) [text/plain]\n",
            "Saving to: ‘tokenizer.json’\n",
            "\n",
            "tokenizer.json      100%[===================>]   1.76M  1.77MB/s    in 1.0s    \n",
            "\n",
            "2024-03-04 12:36:37 (1.77 MB/s) - ‘tokenizer.json’ saved [1843427/1843427]\n",
            "\n",
            "--2024-03-04 12:36:37--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer.model\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.5, 13.35.7.38, 13.35.7.81, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/45ccb9c8b6b561889acea59191d66986d314e7cbd6a78abc6e49b139ca91c1e6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27tokenizer.model%3B+filename%3D%22tokenizer.model%22%3B&Expires=1709814935&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTgxNDkzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzQ1Y2NiOWM4YjZiNTYxODg5YWNlYTU5MTkxZDY2OTg2ZDMxNGU3Y2JkNmE3OGFiYzZlNDliMTM5Y2E5MWMxZTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=JbkVET83wq%7EoNsIHqcWkvUifjqtWAcnEpopKYqFHOsQp2e-kgJY%7EiwmxbZIazKphvQPGdwNBTg71Rcv8Ik3bJDuTeDBwnKmE7Y%7EpMfUZC1tu%7Ek3Uab8IbqjBgqI9RmrF%7ERU2EN880a7AEPyMTJ65PlPK1TJRgcKuzeRqKsEYK-G8gpA2uuUDAamGu94K6e0HWdwhkrj5UBtcRIh1g-9dM6uGbm5J8VLHOBdRTDnvfKdURPID4SdM9-fCwDRj5ShaclPuINulO3pYlhM5SVtLU3os%7EJljx3veH6A7Pfv5yDYWPHUiFWonYNIe%7E8edmblP8bncth7lKoYw53hxVTjFUQ__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2024-03-04 12:36:38--  https://cdn-lfs.huggingface.co/repos/b4/bd/b4bd4393a105f214fbffbc463d5cd2eb652c6e78e3531c683d7450c0ca368bde/45ccb9c8b6b561889acea59191d66986d314e7cbd6a78abc6e49b139ca91c1e6?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27tokenizer.model%3B+filename%3D%22tokenizer.model%22%3B&Expires=1709814935&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTgxNDkzNX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy9iNC9iZC9iNGJkNDM5M2ExMDVmMjE0ZmJmZmJjNDYzZDVjZDJlYjY1MmM2ZTc4ZTM1MzFjNjgzZDc0NTBjMGNhMzY4YmRlLzQ1Y2NiOWM4YjZiNTYxODg5YWNlYTU5MTkxZDY2OTg2ZDMxNGU3Y2JkNmE3OGFiYzZlNDliMTM5Y2E5MWMxZTY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=JbkVET83wq%7EoNsIHqcWkvUifjqtWAcnEpopKYqFHOsQp2e-kgJY%7EiwmxbZIazKphvQPGdwNBTg71Rcv8Ik3bJDuTeDBwnKmE7Y%7EpMfUZC1tu%7Ek3Uab8IbqjBgqI9RmrF%7ERU2EN880a7AEPyMTJ65PlPK1TJRgcKuzeRqKsEYK-G8gpA2uuUDAamGu94K6e0HWdwhkrj5UBtcRIh1g-9dM6uGbm5J8VLHOBdRTDnvfKdURPID4SdM9-fCwDRj5ShaclPuINulO3pYlhM5SVtLU3os%7EJljx3veH6A7Pfv5yDYWPHUiFWonYNIe%7E8edmblP8bncth7lKoYw53hxVTjFUQ__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.35.7.14, 13.35.7.113, 13.35.7.99, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.35.7.14|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 500058 (488K) [binary/octet-stream]\n",
            "Saving to: ‘tokenizer.model’\n",
            "\n",
            "tokenizer.model     100%[===================>] 488.34K   612KB/s    in 0.8s    \n",
            "\n",
            "2024-03-04 12:36:39 (612 KB/s) - ‘tokenizer.model’ saved [500058/500058]\n",
            "\n",
            "--2024-03-04 12:36:40--  https://huggingface.co/codellama/CodeLlama-7b-hf/resolve/main/tokenizer_config.json\n",
            "Resolving huggingface.co (huggingface.co)... 13.35.7.5, 13.35.7.38, 13.35.7.81, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.35.7.5|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 749 [text/plain]\n",
            "Saving to: ‘tokenizer_config.json’\n",
            "\n",
            "tokenizer_config.js 100%[===================>]     749  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-04 12:36:40 (519 MB/s) - ‘tokenizer_config.json’ saved [749/749]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBHWr2mbJQHi",
        "outputId": "34a91e6f-e01b-47e0-a58d-82a8fbe6ffe2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui/models\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/facebookresearch/llama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ohVcccUXJc_k",
        "outputId": "0fa35511-12b1-4d3c-bcca-b5fbd5499a90"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'llama'...\n",
            "remote: Enumerating objects: 434, done.\u001b[K\n",
            "remote: Counting objects: 100% (17/17), done.\u001b[K\n",
            "remote: Compressing objects: 100% (13/13), done.\u001b[K\n",
            "remote: Total 434 (delta 4), reused 12 (delta 3), pack-reused 417\u001b[K\n",
            "Receiving objects: 100% (434/434), 1.10 MiB | 3.79 MiB/s, done.\n",
            "Resolving deltas: 100% (222/222), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/text-generation-webui/models/llama"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0FTm6LM8Jsw2",
        "outputId": "801b81d5-1516-449e-fbdf-da5620b775b1"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui/models/llama\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash download.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c3UzZ_vNLAK",
        "outputId": "b40e6a25-1f29-40be-92c2-5f25cacc196f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the URL from email: https://download.llamameta.net/*?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidTRiOW03MG1jcDM0NG1yZDh4N2h4MDM1IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTY0MTU0NX19fV19&Signature=VntAUV3s1yvSgOthMDi6VrbFZ5%7EpHkbqLLbDo3GL6laMS2ArCDLxWFYrNzujKEpomRtUPCvjxp66I%7EjZbiK90zGvVUpPM-z%7EyifDrtDCsOMhEiU6533HmqLJqiClxUdNkDo0j6tsDQ3YGvIJd9H0p3UXXkwpf9SCcZx%7EoQsNQZK03pkySW0PjG9hSm8zU65IGolDL0AYXnhqwuOZsRENJf1myC23nYt8QDN4Q2VqxHInHOo0CAUP%7ElbL1M9hF-KO51mocaCzkvLoughynsmRvVL2-hFxjhbxOtLXjEbrzuSLSllvX%7EWo4kOvFTM%7EJJM4mGIVyBdb90NRIMBYoX18cw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=417148797458511\n",
            "\n",
            "Enter the list of models to download without spaces (7B,13B,70B,7B-chat,13B-chat,70B-chat), or press Enter for all: 7B-chat\n",
            "Downloading LICENSE and Acceptable Usage Policy\n",
            "--2024-03-04 12:47:07--  https://download.llamameta.net/LICENSE?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidTRiOW03MG1jcDM0NG1yZDh4N2h4MDM1IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTY0MTU0NX19fV19&Signature=VntAUV3s1yvSgOthMDi6VrbFZ5%7EpHkbqLLbDo3GL6laMS2ArCDLxWFYrNzujKEpomRtUPCvjxp66I%7EjZbiK90zGvVUpPM-z%7EyifDrtDCsOMhEiU6533HmqLJqiClxUdNkDo0j6tsDQ3YGvIJd9H0p3UXXkwpf9SCcZx%7EoQsNQZK03pkySW0PjG9hSm8zU65IGolDL0AYXnhqwuOZsRENJf1myC23nYt8QDN4Q2VqxHInHOo0CAUP%7ElbL1M9hF-KO51mocaCzkvLoughynsmRvVL2-hFxjhbxOtLXjEbrzuSLSllvX%7EWo4kOvFTM%7EJJM4mGIVyBdb90NRIMBYoX18cw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=417148797458511\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 13.35.35.71, 13.35.35.83, 13.35.35.22, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|13.35.35.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-03-04 12:47:07--  https://download.llamameta.net/USE_POLICY.md?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidTRiOW03MG1jcDM0NG1yZDh4N2h4MDM1IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTY0MTU0NX19fV19&Signature=VntAUV3s1yvSgOthMDi6VrbFZ5%7EpHkbqLLbDo3GL6laMS2ArCDLxWFYrNzujKEpomRtUPCvjxp66I%7EjZbiK90zGvVUpPM-z%7EyifDrtDCsOMhEiU6533HmqLJqiClxUdNkDo0j6tsDQ3YGvIJd9H0p3UXXkwpf9SCcZx%7EoQsNQZK03pkySW0PjG9hSm8zU65IGolDL0AYXnhqwuOZsRENJf1myC23nYt8QDN4Q2VqxHInHOo0CAUP%7ElbL1M9hF-KO51mocaCzkvLoughynsmRvVL2-hFxjhbxOtLXjEbrzuSLSllvX%7EWo4kOvFTM%7EJJM4mGIVyBdb90NRIMBYoX18cw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=417148797458511\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 13.35.35.71, 13.35.35.83, 13.35.35.22, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|13.35.35.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "Downloading tokenizer\n",
            "--2024-03-04 12:47:07--  https://download.llamameta.net/tokenizer.model?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidTRiOW03MG1jcDM0NG1yZDh4N2h4MDM1IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTY0MTU0NX19fV19&Signature=VntAUV3s1yvSgOthMDi6VrbFZ5%7EpHkbqLLbDo3GL6laMS2ArCDLxWFYrNzujKEpomRtUPCvjxp66I%7EjZbiK90zGvVUpPM-z%7EyifDrtDCsOMhEiU6533HmqLJqiClxUdNkDo0j6tsDQ3YGvIJd9H0p3UXXkwpf9SCcZx%7EoQsNQZK03pkySW0PjG9hSm8zU65IGolDL0AYXnhqwuOZsRENJf1myC23nYt8QDN4Q2VqxHInHOo0CAUP%7ElbL1M9hF-KO51mocaCzkvLoughynsmRvVL2-hFxjhbxOtLXjEbrzuSLSllvX%7EWo4kOvFTM%7EJJM4mGIVyBdb90NRIMBYoX18cw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=417148797458511\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 13.35.35.71, 13.35.35.83, 13.35.35.22, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|13.35.35.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "--2024-03-04 12:47:07--  https://download.llamameta.net/tokenizer_checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidTRiOW03MG1jcDM0NG1yZDh4N2h4MDM1IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTY0MTU0NX19fV19&Signature=VntAUV3s1yvSgOthMDi6VrbFZ5%7EpHkbqLLbDo3GL6laMS2ArCDLxWFYrNzujKEpomRtUPCvjxp66I%7EjZbiK90zGvVUpPM-z%7EyifDrtDCsOMhEiU6533HmqLJqiClxUdNkDo0j6tsDQ3YGvIJd9H0p3UXXkwpf9SCcZx%7EoQsNQZK03pkySW0PjG9hSm8zU65IGolDL0AYXnhqwuOZsRENJf1myC23nYt8QDN4Q2VqxHInHOo0CAUP%7ElbL1M9hF-KO51mocaCzkvLoughynsmRvVL2-hFxjhbxOtLXjEbrzuSLSllvX%7EWo4kOvFTM%7EJJM4mGIVyBdb90NRIMBYoX18cw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=417148797458511\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 13.35.35.71, 13.35.35.83, 13.35.35.22, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|13.35.35.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 416 Requested Range Not Satisfiable\n",
            "\n",
            "    The file is already fully retrieved; nothing to do.\n",
            "\n",
            "tokenizer.model: OK\n",
            "Downloading llama-2-7b-chat\n",
            "--2024-03-04 12:47:07--  https://download.llamameta.net/llama-2-7b-chat/consolidated.00.pth?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidTRiOW03MG1jcDM0NG1yZDh4N2h4MDM1IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTY0MTU0NX19fV19&Signature=VntAUV3s1yvSgOthMDi6VrbFZ5%7EpHkbqLLbDo3GL6laMS2ArCDLxWFYrNzujKEpomRtUPCvjxp66I%7EjZbiK90zGvVUpPM-z%7EyifDrtDCsOMhEiU6533HmqLJqiClxUdNkDo0j6tsDQ3YGvIJd9H0p3UXXkwpf9SCcZx%7EoQsNQZK03pkySW0PjG9hSm8zU65IGolDL0AYXnhqwuOZsRENJf1myC23nYt8QDN4Q2VqxHInHOo0CAUP%7ElbL1M9hF-KO51mocaCzkvLoughynsmRvVL2-hFxjhbxOtLXjEbrzuSLSllvX%7EWo4kOvFTM%7EJJM4mGIVyBdb90NRIMBYoX18cw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=417148797458511\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 13.35.35.71, 13.35.35.83, 13.35.35.22, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|13.35.35.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 13476925163 (13G) [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-7b-chat/consolidated.00.pth’\n",
            "\n",
            "./llama-2-7b-chat/c 100%[===================>]  12.55G   139MB/s    in 94s     \n",
            "\n",
            "2024-03-04 12:48:42 (137 MB/s) - ‘./llama-2-7b-chat/consolidated.00.pth’ saved [13476925163/13476925163]\n",
            "\n",
            "--2024-03-04 12:48:42--  https://download.llamameta.net/llama-2-7b-chat/params.json?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidTRiOW03MG1jcDM0NG1yZDh4N2h4MDM1IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTY0MTU0NX19fV19&Signature=VntAUV3s1yvSgOthMDi6VrbFZ5%7EpHkbqLLbDo3GL6laMS2ArCDLxWFYrNzujKEpomRtUPCvjxp66I%7EjZbiK90zGvVUpPM-z%7EyifDrtDCsOMhEiU6533HmqLJqiClxUdNkDo0j6tsDQ3YGvIJd9H0p3UXXkwpf9SCcZx%7EoQsNQZK03pkySW0PjG9hSm8zU65IGolDL0AYXnhqwuOZsRENJf1myC23nYt8QDN4Q2VqxHInHOo0CAUP%7ElbL1M9hF-KO51mocaCzkvLoughynsmRvVL2-hFxjhbxOtLXjEbrzuSLSllvX%7EWo4kOvFTM%7EJJM4mGIVyBdb90NRIMBYoX18cw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=417148797458511\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 13.35.35.71, 13.35.35.83, 13.35.35.22, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|13.35.35.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 102 [application/json]\n",
            "Saving to: ‘./llama-2-7b-chat/params.json’\n",
            "\n",
            "./llama-2-7b-chat/p 100%[===================>]     102  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-04 12:48:43 (251 KB/s) - ‘./llama-2-7b-chat/params.json’ saved [102/102]\n",
            "\n",
            "--2024-03-04 12:48:43--  https://download.llamameta.net/llama-2-7b-chat/checklist.chk?Policy=eyJTdGF0ZW1lbnQiOlt7InVuaXF1ZV9oYXNoIjoidTRiOW03MG1jcDM0NG1yZDh4N2h4MDM1IiwiUmVzb3VyY2UiOiJodHRwczpcL1wvZG93bmxvYWQubGxhbWFtZXRhLm5ldFwvKiIsIkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTcwOTY0MTU0NX19fV19&Signature=VntAUV3s1yvSgOthMDi6VrbFZ5%7EpHkbqLLbDo3GL6laMS2ArCDLxWFYrNzujKEpomRtUPCvjxp66I%7EjZbiK90zGvVUpPM-z%7EyifDrtDCsOMhEiU6533HmqLJqiClxUdNkDo0j6tsDQ3YGvIJd9H0p3UXXkwpf9SCcZx%7EoQsNQZK03pkySW0PjG9hSm8zU65IGolDL0AYXnhqwuOZsRENJf1myC23nYt8QDN4Q2VqxHInHOo0CAUP%7ElbL1M9hF-KO51mocaCzkvLoughynsmRvVL2-hFxjhbxOtLXjEbrzuSLSllvX%7EWo4kOvFTM%7EJJM4mGIVyBdb90NRIMBYoX18cw__&Key-Pair-Id=K15QRJLYKIFSLZ&Download-Request-ID=417148797458511\n",
            "Resolving download.llamameta.net (download.llamameta.net)... 13.35.35.71, 13.35.35.83, 13.35.35.22, ...\n",
            "Connecting to download.llamameta.net (download.llamameta.net)|13.35.35.71|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 100 [binary/octet-stream]\n",
            "Saving to: ‘./llama-2-7b-chat/checklist.chk’\n",
            "\n",
            "./llama-2-7b-chat/c 100%[===================>]     100  --.-KB/s    in 0s      \n",
            "\n",
            "2024-03-04 12:48:43 (1016 KB/s) - ‘./llama-2-7b-chat/checklist.chk’ saved [100/100]\n",
            "\n",
            "Checking checksums\n",
            "consolidated.00.pth: OK\n",
            "params.json: OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/main/src/transformers/models/llama/convert_llama_weights_to_hf.py\n",
        "!pip install git+https://github.com/huggingface/transformers\n",
        "!pip install accelerate\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2XUQwx3hMna",
        "outputId": "028612a8-73b5-4ecd-a71c-8b7df2b8f528"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-04 12:51:26--  https://raw.githubusercontent.com/huggingface/transformers/main/src/transformers/models/llama/convert_llama_weights_to_hf.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 14165 (14K) [text/plain]\n",
            "Saving to: ‘convert_llama_weights_to_hf.py’\n",
            "\n",
            "convert_llama_weigh 100%[===================>]  13.83K  --.-KB/s    in 0.002s  \n",
            "\n",
            "2024-03-04 12:51:26 (6.52 MB/s) - ‘convert_llama_weights_to_hf.py’ saved [14165/14165]\n",
            "\n",
            "Collecting git+https://github.com/huggingface/transformers\n",
            "  Cloning https://github.com/huggingface/transformers to /tmp/pip-req-build-udds1rkz\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers /tmp/pip-req-build-udds1rkz\n",
            "  Resolved https://github.com/huggingface/transformers to commit 1681a6d452b60ff3652a96f03541dfa491124192\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (2023.12.25)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.39.0.dev0) (4.66.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.19.3->transformers==4.39.0.dev0) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.39.0.dev0) (2024.2.2)\n",
            "Requirement already satisfied: accelerate in /usr/local/lib/python3.10/dist-packages (0.27.2)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from accelerate) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from accelerate) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate) (2.1.0+cu121)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate) (2.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub->accelerate) (4.66.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python convert_llama_weights_to_hf.py \\\n",
        "    --input_dir /content/text-generation-webui/models/llama/llama-2-7b  --model_size 7B --output_dir /content/text-generation-webui/models/llama/llama-2-7bhf/7B"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sI98WLVwha5E",
        "outputId": "e710589c-30e2-4027-86d0-3b968d9ab571"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are using the default legacy behaviour of the <class 'transformers.models.llama.tokenization_llama.LlamaTokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n",
            "Fetching all parameters from the checkpoint at /content/text-generation-webui/models/llama/llama-2-7b/7B.\n",
            "Loading the checkpoint in a Llama model.\n",
            "Loading checkpoint shards:   0% 0/33 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
            "  return self.fget.__get__(instance, owner)()\n",
            "Loading checkpoint shards: 100% 33/33 [00:02<00:00, 13.08it/s]\n",
            "Saving in the Transformers format.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/text-generation-webui"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoPPR7WbJwpn",
        "outputId": "560ea2fa-b2da-4e15-d888-f89e7a8f55a6"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/text-generation-webui\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python server.py --share"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9dTs7gjKWVz",
        "outputId": "cac6b982-2321-42a6-880a-538da84b31eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2;36m13:01:59-641530\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Starting Text generation web UI                                            \n",
            "\u001b[2;36m13:01:59-646083\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading the extension \u001b[32m\"gallery\"\u001b[0m                                            \n",
            "\n",
            "Running on local URL:  http://127.0.0.1:7860\n",
            "\n",
            "Running on public URL: https://d11c7bdc2e177a559a.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n",
            "\u001b[2;36m13:03:10-779745\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading \u001b[32m\"llama-2-7bhf\"\u001b[0m                                                     \n",
            "\u001b[2;36m13:03:10-793926\u001b[0m\u001b[2;36m \u001b[0m\u001b[1;31mERROR   \u001b[0m Failed to load the model.                                                  \n",
            "Traceback (most recent call last):\n",
            "  File \"/content/text-generation-webui/modules/ui_model_menu.py\", line 242, in load_model_wrapper\n",
            "    shared.model, shared.tokenizer = load_model(selected_model, loader)\n",
            "  File \"/content/text-generation-webui/modules/models.py\", line 87, in load_model\n",
            "    output = load_func_map[loader](model_name)\n",
            "  File \"/content/text-generation-webui/modules/models.py\", line 140, in huggingface_loader\n",
            "    config = AutoConfig.from_pretrained(path_to_model, trust_remote_code=params['trust_remote_code'])\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/models/auto/configuration_auto.py\", line 1117, in from_pretrained\n",
            "    config_dict, unused_kwargs = PretrainedConfig.get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 631, in get_config_dict\n",
            "    config_dict, kwargs = cls._get_config_dict(pretrained_model_name_or_path, **kwargs)\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/configuration_utils.py\", line 686, in _get_config_dict\n",
            "    resolved_config_file = cached_file(\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/transformers/utils/hub.py\", line 369, in cached_file\n",
            "    raise EnvironmentError(\n",
            "OSError: models/llama-2-7bhf does not appear to have a file named config.json. Checkout 'https://huggingface.co/models/llama-2-7bhf/tree/None' for available files.\n",
            "\n",
            "\u001b[2;36m13:05:10-116671\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading \u001b[32m\"llama-2-7bhf\"\u001b[0m                                                     \n",
            "Loading checkpoint shards: 100% 3/3 [00:04<00:00,  1.36s/it]\n",
            "\u001b[2;36m13:05:18-950960\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m LOADER: \u001b[32m\"Transformers\"\u001b[0m                                                     \n",
            "\u001b[2;36m13:05:18-952327\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m TRUNCATION LENGTH: \u001b[1;36m2048\u001b[0m                                                    \n",
            "\u001b[2;36m13:05:18-953331\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m INSTRUCTION TEMPLATE: \u001b[32m\"Alpaca\"\u001b[0m                                             \n",
            "\u001b[2;36m13:05:18-954244\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loaded the model in \u001b[1;36m8.84\u001b[0m seconds.                                          \n",
            "Output generated in 4.21 seconds (3.56 tokens/s, 15 tokens, context 69, seed 620164113)\n"
          ]
        }
      ]
    }
  ]
}